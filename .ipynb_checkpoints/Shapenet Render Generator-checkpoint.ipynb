{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapenet Rendering\n",
    "- Blender script source: https://github.com/panmari/stanford-shapenet-renderer\n",
    "\n",
    "## Semantic Segmentation\n",
    "References:\n",
    "- https://blender.stackexchange.com/questions/79595/change-diffuse-shader-to-emission-shader-without-affecting-shader-color\n",
    "- https://blender.stackexchange.com/questions/80906/create-a-segmentation-picture-with-each-object-class-rendered-in-different-color/162746#162746\n",
    "- https://blender.stackexchange.com/questions/34609/is-there-a-way-to-streamline-scripting-these-shaders-and-modifier-keyframes\n",
    "- https://github.com/DIYer22/bpycv#install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import imageio\n",
    "import shutil\n",
    "\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "from modules.ShapeNet import ShapeNetHandler\n",
    "import modules.utils\n",
    "import modules.BackgroundImages\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ShapeNet Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapenet_root = \"/hdd/mliuzzolino/ShapeNet/data/ShapeNetCore.v2\"\n",
    "shapenet_handler = ShapeNetHandler(shapenet_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print available categories by name\n",
    "- Can use name to condition random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapenet_handler.print_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly Sample a filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_obj_filepath, temp_synset_id, temp_instance_id, temp_obj_name = shapenet_handler.sample_obj(category_name='car')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_OUTPUT_ROOT = 'render_output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N_VIEW_ANGLES = 72\n",
    "_N_MODELS_TO_RENDER = 200\n",
    "_RANDOM_SCALING = False\n",
    "_OVERWRITE = True\n",
    "_LAMP_MODE = 'random'\n",
    "_RENDER_ENGINE = 'BLENDER_RENDER' # 'CYCLES', 'BLENDER_RENDER'\n",
    "_RENDER_SCRIPT = \"scripts/blender_render.py\"\n",
    "_TARGET_CATEGORY_LIST = []#['airplane', 'car']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess_outputs = []\n",
    "try:\n",
    "    for img_i in range(_N_MODELS_TO_RENDER):\n",
    "        # Randomly select target category\n",
    "        target_category = ''\n",
    "        if _TARGET_CATEGORY_LIST != []:\n",
    "            target_category = np.random.choice(_TARGET_CATEGORY_LIST)\n",
    "        \n",
    "        # Sample object filepath\n",
    "        obj_filepath, synset_id, instance_id, obj_name = shapenet_handler.sample_obj(category_name=target_category)\n",
    "        \n",
    "        # Setup outpath\n",
    "        output_root = os.path.join(_OUTPUT_ROOT, _RENDER_ENGINE, f'synsetID_{synset_id}', instance_id)\n",
    "        \n",
    "        # Randomly select obj scaling\n",
    "        random_scale = np.random.uniform(0.99, 1.15) if _RANDOM_SCALING else 1.0\n",
    "        random_n_occlusions = 0#np.random.randint(3, 7)\n",
    "        \n",
    "        if not os.path.exists(output_root) or _OVERWRITE:\n",
    "            # Remove previous directory if overwrite\n",
    "            if _OVERWRITE and os.path.exists(output_root):\n",
    "                shutil.rmtree(output_root)\n",
    "            \n",
    "            # Run blender script\n",
    "            cmd = f\"blender --background --python {_RENDER_SCRIPT} -- \"\n",
    "            cmd += f\"--output_folder {output_root} --views {_N_VIEW_ANGLES} \"\n",
    "            cmd += f\"--scale {random_scale} --n_occlusions {random_n_occlusions} \"\n",
    "            cmd += f\"--render_engine {_RENDER_ENGINE} \"\n",
    "            cmd += f\"--lamp_mode {_LAMP_MODE} \" \n",
    "            cmd += f\"{obj_filepath}\"\n",
    "            out = subprocess.check_output(cmd.split(\" \"), shell=False)\n",
    "            subprocess_outputs.append(out)\n",
    "        else:\n",
    "            print(\"Skipping.\")\n",
    "        \n",
    "        # Stdout\n",
    "        stdout_str = f\"[{img_i+1}/{_N_MODELS_TO_RENDER}] -- \"\n",
    "        stdout_str += f\"SynsetID: {synset_id} -- \"\n",
    "        stdout_str += f\"InstanceID: {instance_id:32s} -- \"\n",
    "        stdout_str += f\"Name: {obj_name}\"\n",
    "        print(stdout_str)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    try:\n",
    "        # Try to cleanup directory with incomplete # renders\n",
    "        if len(os.listdir(output_root)) != _N_VIEW_ANGLES:\n",
    "            shutil.rmtree(output_root)\n",
    "    except:\n",
    "        pass\n",
    "    print(\"\\nEnding early.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building image paths...\n"
     ]
    }
   ],
   "source": [
    "background_params = {\n",
    "    \"root\"               : '/hdd/mliuzzolino/Places2/places365_standard/train',\n",
    "    \"labels_root\"        : '/hdd/mliuzzolino/Places2/predicted_labels',\n",
    "    \"mode\"               : \"include\", # \"include\", \"exclude\"\n",
    "    \"classes_specified\"  : ['pizza']# ['washbasin', 'tennis_ball', 'broccoli']\n",
    "}\n",
    "background = modules.BackgroundImages.BackgroundHandler(**background_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Normal Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LOAD_LIMIT = 6\n",
    "\n",
    "limit_reached = False\n",
    "\n",
    "all_imgs = []\n",
    "rendered_instance_ids = glob.glob(f\"{os.path.join(_OUTPUT_ROOT, _RENDER_ENGINE)}/*/*\")\n",
    "np.random.shuffle(rendered_instance_ids)\n",
    "for rendered_instance_id in rendered_instance_ids:\n",
    "    sys.stdout.write(f\"\\rProcessed model {len(all_imgs)+1}/{_LOAD_LIMIT}...\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Load paths\n",
    "    target_img_paths = np.sort(glob.glob(f\"{rendered_instance_id}/*_target.png\"))\n",
    "\n",
    "    # Load images\n",
    "    target_imgs = [modules.utils.read_image(img_path, parse_mask=True) for img_path in target_img_paths]\n",
    "\n",
    "    # Ensure correct number of view angles present\n",
    "    if len(target_imgs) != _N_VIEW_ANGLES:\n",
    "        print(f\"\\t**Error: Insufficient angles! Actual: {len(target_imgs)} - Expected: {_N_VIEW_ANGLES}\")\n",
    "        continue\n",
    "\n",
    "    # Setup background image\n",
    "    \n",
    "    background_img = background.sample(target_imgs[0][0].shape)\n",
    "    #modules.utils.sample_background_img(background_img_paths, shape=target_imgs[0][0].shape)\n",
    "\n",
    "    # Apply background image\n",
    "    target_imgs = [(modules.utils.add_background(rgb_img, seg_img, background_img), seg_img)\n",
    "                         for rgb_img, seg_img in target_imgs]\n",
    "    \n",
    "    # Combine images\n",
    "    joined_imgs = modules.utils.combine_imgs(target_imgs)\n",
    "    all_imgs.append(joined_imgs)\n",
    "\n",
    "    # Check limit\n",
    "    if len(all_imgs) >= _LOAD_LIMIT:\n",
    "        print(\"\\nLimit reached. Ending early.\")\n",
    "        limit_reached = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all images\n",
    "stacked_imgs = modules.utils.stack_all_imgs(all_imgs, nrow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = 'test.gif'\n",
    "animation = modules.utils.toAnimation(stacked_imgs, figsize=(12,12), interval=100, savepath=savepath, fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savepath.endswith('gif'):\n",
    "    display(Image(filename=savepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview Occluded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LOAD_LIMIT = 18\n",
    "\n",
    "limit_reached = False\n",
    "\n",
    "all_imgs = []\n",
    "rendered_instance_ids = glob.glob(f\"{os.path.join(_OUTPUT_ROOT, _RENDER_ENGINE)}/*/*\")\n",
    "np.random.shuffle(rendered_instance_ids)\n",
    "for rendered_instance_id in rendered_instance_ids:\n",
    "    sys.stdout.write(f\"\\rProcessed model {len(all_imgs)+1}/{_LOAD_LIMIT}...\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Load paths\n",
    "    target_img_paths = np.sort(glob.glob(f\"{rendered_instance_id}/*_target.png\"))\n",
    "    occluded_img_paths = [ele.replace('_target', '_occluded') for ele in target_img_paths]\n",
    "    semantic_seg_paths = [ele.replace('_target', '_semseg') for ele in target_img_paths]\n",
    "    \n",
    "\n",
    "    # Load images\n",
    "    target_imgs = [modules.utils.read_image(img_path, parse_mask=True) for img_path in target_img_paths]\n",
    "    occluded_imgs = [modules.utils.read_image(img_path) for img_path in occluded_img_paths]\n",
    "    segmentation_imgs = [modules.utils.read_image(img_path) for img_path in semantic_seg_paths]\n",
    "\n",
    "    # Ensure correct number of view angles present\n",
    "    if len(target_imgs) != _N_VIEW_ANGLES:\n",
    "        print(f\"\\t**Error: Insufficient angles! Actual: {len(target_imgs)} - Expected: {_N_VIEW_ANGLES}\")\n",
    "        continue\n",
    "\n",
    "    # Setup background image\n",
    "    background_img = modules.utils.sample_background_img(background_img_paths, shape=target_imgs[0].shape)\n",
    "\n",
    "    # Apply background image\n",
    "    target_imgs = [modules.utils.add_background(rgb_img, seg_img, background_img) \n",
    "                         for rgb_img, seg_img in target_imgs]\n",
    "    occluded_imgs = [modules.utils.add_background(rgb_img, seg_img, background_img)\n",
    "                         for rgb_img, seg_img in zip(occluded_imgs, segmentation_imgs)]\n",
    "\n",
    "    # Join rgb image with semantic seg image\n",
    "    joined_imgs = [(target, occluded, mask)\n",
    "                       for target, occluded, mask in zip(target_imgs, occluded_imgs, segmentation_imgs)]\n",
    "\n",
    "    # Combine images\n",
    "    joined_imgs = modules.utils.combine_imgs(joined_imgs)\n",
    "    all_imgs.append(joined_imgs)\n",
    "\n",
    "    # Check limit\n",
    "    if len(all_imgs) >= _LOAD_LIMIT:\n",
    "        print(\"\\nLimit reached. Ending early.\")\n",
    "        limit_reached = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all images\n",
    "stacked_imgs = modules.utils.stack_all_imgs(all_imgs, nrow=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = 'test.gif'\n",
    "animation = modules.utils.toAnimation(stacked_imgs, figsize=(12,12), interval=100, savepath=savepath, fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savepath.endswith('gif'):\n",
    "    display(Image(filename=savepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
