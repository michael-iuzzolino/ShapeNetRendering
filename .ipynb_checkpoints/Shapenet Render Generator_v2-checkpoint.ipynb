{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapenet Rendering\n",
    "- Blender script source: https://github.com/panmari/stanford-shapenet-renderer\n",
    "\n",
    "## Semantic Segmentation\n",
    "References:\n",
    "- https://blender.stackexchange.com/questions/79595/change-diffuse-shader-to-emission-shader-without-affecting-shader-color\n",
    "- https://blender.stackexchange.com/questions/80906/create-a-segmentation-picture-with-each-object-class-rendered-in-different-color/162746#162746\n",
    "- https://blender.stackexchange.com/questions/34609/is-there-a-way-to-streamline-scripting-these-shaders-and-modifier-keyframes\n",
    "- https://github.com/DIYer22/bpycv#install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import imageio\n",
    "import shutil\n",
    "\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "import modules.ShapeNet\n",
    "import modules.utils\n",
    "import modules.BackgroundImages\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ShapeNet Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading taxonomy from /hdd/mliuzzolino/ShapeNet/data/ShapeNetCore.v2/taxonomy.json...\n",
      "Building synset to name lookup.\n",
      "Setting up model folders\n",
      "Loading folder /hdd/mliuzzolino/ShapeNet/data/ShapeNetCore.v2/03467517 [55/55]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shapenet_root = \"/hdd/mliuzzolino/ShapeNet/data/ShapeNetCore.v2\"\n",
    "shapenet_handler = modules.ShapeNet.Handler(shapenet_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print available categories by name\n",
    "- Can use name to condition random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapenet_handler.print_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly Sample a filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_obj_filepath, temp_synset_id, temp_instance_id, temp_obj_name = shapenet_handler.sample_obj(category_name='car')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building image paths...\n",
      "Loading labeled path lookup...\n"
     ]
    }
   ],
   "source": [
    "background_params = {\n",
    "    \"root\"               : '/hdd/mliuzzolino/Places2/places365_standard/train',\n",
    "    \"labels_root\"        : '/hdd/mliuzzolino/Places2/predicted_labels',\n",
    "    \"eval_model\"         : 'resnet18'\n",
    "}\n",
    "background = modules.BackgroundImages.BackgroundHandler(**background_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background.list_possible_filter_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 1,803,460 -- Final: 1,803,460 -- Num Filtered: 0\n",
      "Finished setup.\n"
     ]
    }
   ],
   "source": [
    "classes_specified = [] # ['acoustic_guitar']\n",
    "background.filter_img_paths_by_class(mode='include', classes_specified=classes_specified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MODE = 'generate' # demo, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_OUTPUT_ROOT = 'render_output'\n",
    "if not os.path.exists(_OUTPUT_ROOT):\n",
    "    os.mkdir(_OUTPUT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N_VIEW_ANGLES = 72\n",
    "_N_MODELS_TO_RENDER = 10\n",
    "_RANDOM_SCALING = False\n",
    "_OCCLUSIONS_ACTIVE = False\n",
    "_OVERWRITE = True\n",
    "_OVERWRITE_ALL = True\n",
    "_LAMP_MODE = 'random' if _MODE == 'generate' else 'follow_camera'\n",
    "_RENDER_ENGINE = 'BLENDER_RENDER' # 'CYCLES', 'BLENDER_RENDER'\n",
    "_RENDER_SCRIPT = \"/home/michael/ShapeNetRendering/scripts/blender_render.py\"\n",
    "_TARGET_CATEGORY_LIST = ['car', 'airplane']#['airplane', 'car']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] -- SynsetID: 02691156 -- InstanceID: f186d2998485c6ed5e9e2656aff7dd5b -- Name: airplane,aeroplane,plane\n",
      "[2/10] -- SynsetID: 02691156 -- InstanceID: 3764de22af04fd32a993db466b6d73d3 -- Name: airplane,aeroplane,plane\n",
      "[3/10] -- SynsetID: 02958343 -- InstanceID: 67a3dfa9fb2d1f2bbda733a39f84326d -- Name: car,auto,automobile,machine,motorcar\n",
      "[4/10] -- SynsetID: 02958343 -- InstanceID: 115170b8b44f9e2e5b2bb28aa7453162 -- Name: car,auto,automobile,machine,motorcar\n",
      "[5/10] -- SynsetID: 02691156 -- InstanceID: 177ea8d43905b1646ee4da51ee0005c9 -- Name: airplane,aeroplane,plane\n",
      "[6/10] -- SynsetID: 02958343 -- InstanceID: 30f0ba361010ea11e66cabd11ba41eae -- Name: car,auto,automobile,machine,motorcar\n",
      "[7/10] -- SynsetID: 02958343 -- InstanceID: 227ab69792241382acfaf62fe6ca656  -- Name: car,auto,automobile,machine,motorcar\n",
      "[8/10] -- SynsetID: 02691156 -- InstanceID: e55224bb456066c618d508b491dafd46 -- Name: airplane,aeroplane,plane\n",
      "[9/10] -- SynsetID: 02958343 -- InstanceID: e999dfb757ddca4830e7f6cd6fb3f1b9 -- Name: car,auto,automobile,machine,motorcar\n",
      "[10/10] -- SynsetID: 02958343 -- InstanceID: 38b80589a780fc3af63ee8a34069b7c5 -- Name: car,auto,automobile,machine,motorcar\n"
     ]
    }
   ],
   "source": [
    "subprocess_outputs = []\n",
    "try:\n",
    "    for img_i in range(_N_MODELS_TO_RENDER):\n",
    "        # Randomly select target category\n",
    "        target_category = ''\n",
    "        if _TARGET_CATEGORY_LIST != []:\n",
    "            target_category = np.random.choice(_TARGET_CATEGORY_LIST)\n",
    "        \n",
    "        # Sample object filepath\n",
    "        obj_filepath, synset_id, instance_id, obj_name = shapenet_handler.sample_obj(category_name=target_category)\n",
    "        \n",
    "        # Setup outpath\n",
    "        base_root = os.path.join(_OUTPUT_ROOT, _MODE, _RENDER_ENGINE)\n",
    "        output_root = os.path.join(base_root, f'synsetID_{synset_id}', instance_id)\n",
    "#         if not os.path.exists(output_root):\n",
    "#             os.makedirs(output_root)\n",
    "        \n",
    "        # Randomly select obj scaling\n",
    "        random_scale = np.random.uniform(0.99, 1.15) if _RANDOM_SCALING else 1.0\n",
    "        random_n_occlusions = np.random.randint(3, 7) if _OCCLUSIONS_ACTIVE else 0 \n",
    "        \n",
    "        if not os.path.exists(output_root) or _OVERWRITE:\n",
    "            if _OVERWRITE_ALL:\n",
    "                shutil.rmtree(base_root)\n",
    "                # Only apply once!\n",
    "                _OVERWRITE_ALL = False\n",
    "            # Remove previous directory if overwrite\n",
    "            if _OVERWRITE and os.path.exists(output_root):\n",
    "                shutil.rmtree(output_root)\n",
    "            \n",
    "            # Run blender script\n",
    "            cmd = f\"blender --background --python {_RENDER_SCRIPT} -- \"\n",
    "            cmd += f\"--output_folder {output_root} --views {_N_VIEW_ANGLES} \"\n",
    "            cmd += f\"--render_mode {_MODE} \"\n",
    "            cmd += f\"--scale {random_scale} --n_occlusions {random_n_occlusions} \"\n",
    "            cmd += f\"--render_engine {_RENDER_ENGINE} \"\n",
    "            cmd += f\"--lamp_mode {_LAMP_MODE} \" \n",
    "            cmd += f\"{obj_filepath}\"\n",
    "            out = subprocess.check_output(cmd.split(\" \"), shell=False)\n",
    "            subprocess_outputs.append(out)\n",
    "        else:\n",
    "            print(\"Skipping.\")\n",
    "        \n",
    "        # Stdout\n",
    "        stdout_str = f\"[{img_i+1}/{_N_MODELS_TO_RENDER}] -- \"\n",
    "        stdout_str += f\"SynsetID: {synset_id} -- \"\n",
    "        stdout_str += f\"InstanceID: {instance_id:32s} -- \"\n",
    "        stdout_str += f\"Name: {obj_name}\"\n",
    "        print(stdout_str)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    try:\n",
    "        # Try to cleanup directory with incomplete # renders\n",
    "        if len(os.listdir(output_root)) != _N_VIEW_ANGLES:\n",
    "            shutil.rmtree(output_root)\n",
    "    except:\n",
    "        pass\n",
    "    print(\"\\nEnding early.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Normal Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MODE_preview = 'generate' # 'demo', 'generate'\n",
    "_IGNORE_SEG_IMG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model 7/10..."
     ]
    }
   ],
   "source": [
    "_LOAD_LIMIT = 18\n",
    "\n",
    "limit_reached = False\n",
    "\n",
    "all_imgs = []\n",
    "rendered_instance_ids = glob.glob(f\"{os.path.join(_OUTPUT_ROOT, _MODE_preview, _RENDER_ENGINE)}/*/*\")\n",
    "_LOAD_LIMIT = min(len(rendered_instance_ids), _LOAD_LIMIT)\n",
    "np.random.shuffle(rendered_instance_ids)\n",
    "for rendered_instance_id in rendered_instance_ids:\n",
    "    sys.stdout.write(f\"\\rProcessed model {len(all_imgs)+1}/{_LOAD_LIMIT}...\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Load paths\n",
    "    target_img_paths = np.sort(glob.glob(f\"{rendered_instance_id}/*_target.png\"))\n",
    "\n",
    "    # Load images\n",
    "    target_imgs = [modules.utils.read_image(img_path, parse_mask=True) for img_path in target_img_paths]\n",
    "\n",
    "    # Ensure correct number of view angles present\n",
    "    if len(target_imgs) != _N_VIEW_ANGLES:\n",
    "        print(f\"\\t**Error: Insufficient angles! Actual: {len(target_imgs)} - Expected: {_N_VIEW_ANGLES}\")\n",
    "        continue\n",
    "\n",
    "    # Setup background image\n",
    "    \n",
    "    background_img = background.sample(target_imgs[0][0].shape)\n",
    "    #modules.utils.sample_background_img(background_img_paths, shape=target_imgs[0][0].shape)\n",
    "\n",
    "    # Apply background image\n",
    "    target_imgs = [(modules.utils.add_background(rgb_img, seg_img, background_img), seg_img)\n",
    "                         for rgb_img, seg_img in target_imgs]\n",
    "    \n",
    "    if _IGNORE_SEG_IMG:\n",
    "        joined_imgs = [ele[0] for ele in target_imgs]\n",
    "    else:\n",
    "        # Combine images\n",
    "        joined_imgs = modules.utils.combine_imgs(target_imgs)\n",
    "    all_imgs.append(joined_imgs)\n",
    "\n",
    "    # Check limit\n",
    "    if len(all_imgs) >= _LOAD_LIMIT:\n",
    "        print(\"\\nLimit reached. Ending early.\")\n",
    "        limit_reached = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all images\n",
    "stacked_imgs = modules.utils.stack_all_imgs(all_imgs, nrow=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = 'test.gif'\n",
    "animation = modules.utils.toAnimation(stacked_imgs, figsize=(12,12), interval=100, savepath=savepath, fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savepath.endswith('gif'):\n",
    "    display(Image(filename=savepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview Occluded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LOAD_LIMIT = 18\n",
    "\n",
    "limit_reached = False\n",
    "\n",
    "all_imgs = []\n",
    "r_path = os.path.join(_OUTPUT_ROOT, 'generate', _RENDER_ENGINE)\n",
    "rendered_instance_ids = glob.glob(f\"{r_path}/*/*\")\n",
    "np.random.shuffle(rendered_instance_ids)\n",
    "for rendered_instance_id in rendered_instance_ids:\n",
    "    sys.stdout.write(f\"\\rProcessed model {len(all_imgs)+1}/{_LOAD_LIMIT}...\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Load paths\n",
    "    target_img_paths = np.sort(glob.glob(f\"{rendered_instance_id}/*_target.png\"))\n",
    "    occluded_img_paths = [ele.replace('_target', '_occluded') for ele in target_img_paths]\n",
    "    semantic_seg_paths = [ele.replace('_target', '_semseg') for ele in target_img_paths]\n",
    "    \n",
    "\n",
    "    # Load images\n",
    "    target_imgs = [modules.utils.read_image(img_path, parse_mask=True) for img_path in target_img_paths]\n",
    "    occluded_imgs = [modules.utils.read_image(img_path) for img_path in occluded_img_paths]\n",
    "    segmentation_imgs = [modules.utils.read_image(img_path) for img_path in semantic_seg_paths]\n",
    "\n",
    "    # Ensure correct number of view angles present\n",
    "    if len(target_imgs) != _N_VIEW_ANGLES:\n",
    "        print(f\"\\t**Error: Insufficient angles! Actual: {len(target_imgs)} - Expected: {_N_VIEW_ANGLES}\")\n",
    "        continue\n",
    "\n",
    "    # Setup background image\n",
    "    background_img = modules.utils.sample_background_img(background_img_paths, shape=target_imgs[0].shape)\n",
    "\n",
    "    # Apply background image\n",
    "    target_imgs = [modules.utils.add_background(rgb_img, seg_img, background_img) \n",
    "                         for rgb_img, seg_img in target_imgs]\n",
    "    occluded_imgs = [modules.utils.add_background(rgb_img, seg_img, background_img)\n",
    "                         for rgb_img, seg_img in zip(occluded_imgs, segmentation_imgs)]\n",
    "\n",
    "    # Join rgb image with semantic seg image\n",
    "    joined_imgs = [(target, occluded, mask)\n",
    "                       for target, occluded, mask in zip(target_imgs, occluded_imgs, segmentation_imgs)]\n",
    "\n",
    "    # Combine images\n",
    "    joined_imgs = modules.utils.combine_imgs(joined_imgs)\n",
    "    all_imgs.append(joined_imgs)\n",
    "\n",
    "    # Check limit\n",
    "    if len(all_imgs) >= _LOAD_LIMIT:\n",
    "        print(\"\\nLimit reached. Ending early.\")\n",
    "        limit_reached = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5e39d42b22f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "all_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7ac60392e273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Stack all images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstacked_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_all_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ShapeNetRendering/modules/utils.py\u001b[0m in \u001b[0;36mstack_all_imgs\u001b[0;34m(all_imgs, nrow)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack_all_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mall_imgs_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mall_imgs_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_imgs_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mstacked_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_imgs_pt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "# Stack all images\n",
    "stacked_imgs = modules.utils.stack_all_imgs(all_imgs, nrow=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = 'test.gif'\n",
    "animation = modules.utils.toAnimation(stacked_imgs, figsize=(12,12), interval=100, savepath=savepath, fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savepath.endswith('gif'):\n",
    "    display(Image(filename=savepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
