{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapenet Rendering\n",
    "- Blender script source: https://github.com/panmari/stanford-shapenet-renderer\n",
    "\n",
    "## Semantic Segmentation\n",
    "If rendering a single object, we get a mask (interpretted as a binary segmentation map) for free. However, if we want to render multiple objects, either for rendering our target object into a 3D scene or for using secondary models to produce oclusions, then we need to do something more. \n",
    "\n",
    "Here are some references for how we can do semantic segmentation:\n",
    "- https://blender.stackexchange.com/questions/79595/change-diffuse-shader-to-emission-shader-without-affecting-shader-color\n",
    "- https://blender.stackexchange.com/questions/80906/create-a-segmentation-picture-with-each-object-class-rendered-in-different-color/162746#162746\n",
    "- https://blender.stackexchange.com/questions/34609/is-there-a-way-to-streamline-scripting-these-shaders-and-modifier-keyframes\n",
    "- https://github.com/DIYer22/bpycv#install\n",
    " - This seems promising, but I had issues when trying to install openexr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import imageio\n",
    "import shutil\n",
    "\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "from modules.ShapeNetHandler import ShapeNetHandler\n",
    "import modules.utils\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ShapeNet Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapenet_root = \"/hdd/mliuzzolino/ShapeNet/data/ShapeNetCore.v2\"\n",
    "shapenet_handler = ShapeNetHandler(shapenet_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print available categories by name\n",
    "- Can use name to condition random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapenet_handler.print_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly Sample a filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_obj_filepath, temp_synset_id, temp_instance_id, temp_obj_name = shapenet_handler.sample_obj(category_name='car')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_OUTPUT_ROOT = 'render_output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N_VIEW_ANGLES = 72\n",
    "_N_MODELS_TO_RENDER = 18\n",
    "_RANDOM_SCALING = False\n",
    "_OVERWRITE = True\n",
    "_RENDER_ENGINE = 'BLENDER_RENDER' # 'CYCLES', 'BLENDER_RENDER'\n",
    "_RENDER_SCRIPT = \"scripts/blender_render.py\"\n",
    "_TARGET_CATEGORY_LIST = ['airplane', 'car']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/18] -- SynsetID: 02958343 -- InstanceID: c4a2e92c4b79ef3140273d3a78e6b502 -- Name: car,auto,automobile,machine,motorcar\n",
      "[2/18] -- SynsetID: 02691156 -- InstanceID: 296c3ee559f87c9354eefcdc602d4520 -- Name: airplane,aeroplane,plane\n",
      "[3/18] -- SynsetID: 02691156 -- InstanceID: 2e3c317357ecb038543941eaaf04581f -- Name: airplane,aeroplane,plane\n",
      "[4/18] -- SynsetID: 02958343 -- InstanceID: 4a536a6a685e08ea678026e3eac5bb0a -- Name: car,auto,automobile,machine,motorcar\n",
      "[5/18] -- SynsetID: 02958343 -- InstanceID: 8cd32df8c0c566b2fbeef84a1ff2df7f -- Name: car,auto,automobile,machine,motorcar\n",
      "[6/18] -- SynsetID: 02691156 -- InstanceID: 167740d2a5f5cb6c7f4561609781d8c9 -- Name: airplane,aeroplane,plane\n",
      "[7/18] -- SynsetID: 02691156 -- InstanceID: c2be303f5abf0db7b3369733e21bbc63 -- Name: airplane,aeroplane,plane\n",
      "[8/18] -- SynsetID: 02691156 -- InstanceID: 7f4a0b23f1256c879a6e43b878d5b335 -- Name: airplane,aeroplane,plane\n",
      "[9/18] -- SynsetID: 02958343 -- InstanceID: f795a928e1c7136f94d732a98738804e -- Name: car,auto,automobile,machine,motorcar\n",
      "[10/18] -- SynsetID: 02691156 -- InstanceID: 28711664a9d08bae46322bce65ca3756 -- Name: airplane,aeroplane,plane\n",
      "[11/18] -- SynsetID: 02958343 -- InstanceID: 17926c1ef484b73e6758a098566bc94e -- Name: car,auto,automobile,machine,motorcar\n",
      "[12/18] -- SynsetID: 02958343 -- InstanceID: 26bc52b1307fca053e5ddfb0ef6345db -- Name: car,auto,automobile,machine,motorcar\n",
      "[13/18] -- SynsetID: 02958343 -- InstanceID: 30f4b931145acc98a3049d0dcf503cdf -- Name: car,auto,automobile,machine,motorcar\n",
      "[14/18] -- SynsetID: 02691156 -- InstanceID: bc3f4d2bf11e1c6382328b5e05417037 -- Name: airplane,aeroplane,plane\n",
      "[15/18] -- SynsetID: 02691156 -- InstanceID: bbc645e0c0449532b3c7301213dfb7   -- Name: airplane,aeroplane,plane\n",
      "[16/18] -- SynsetID: 02691156 -- InstanceID: 9a3cb94af2f2a5b826360e1e29a956c7 -- Name: airplane,aeroplane,plane\n",
      "[17/18] -- SynsetID: 02691156 -- InstanceID: 37ed9b767fb055959d61264e98b74348 -- Name: airplane,aeroplane,plane\n",
      "[18/18] -- SynsetID: 02958343 -- InstanceID: 7db6c18d976e52e451553ea674d2701f -- Name: car,auto,automobile,machine,motorcar\n"
     ]
    }
   ],
   "source": [
    "subprocess_outputs = []\n",
    "try:\n",
    "    for img_i in range(_N_MODELS_TO_RENDER):\n",
    "        # Randomly select target category\n",
    "        target_category = ''\n",
    "        if _TARGET_CATEGORY_LIST != []:\n",
    "            target_category = np.random.choice(_TARGET_CATEGORY_LIST)\n",
    "        \n",
    "        # Sample object filepath\n",
    "        obj_filepath, synset_id, instance_id, obj_name = shapenet_handler.sample_obj(category_name=target_category)\n",
    "        \n",
    "        # Setup outpath\n",
    "        output_root = os.path.join(_OUTPUT_ROOT, _RENDER_ENGINE, f'synsetID_{synset_id}', instance_id)\n",
    "        \n",
    "        # Randomly select obj scaling\n",
    "        random_scale = np.random.uniform(0.99, 1.15) if _RANDOM_SCALING else 1.0\n",
    "        random_n_occlusions = np.random.randint(3, 7)\n",
    "        \n",
    "        if not os.path.exists(output_root) or _OVERWRITE:\n",
    "            # Remove previous directory if overwrite\n",
    "            if _OVERWRITE and os.path.exists(output_root):\n",
    "                shutil.rmtree(output_root)\n",
    "            \n",
    "            # Run blender script\n",
    "            cmd = f\"blender --background --python {_RENDER_SCRIPT} -- \"\n",
    "            cmd += f\"--output_folder {output_root} --views {_N_VIEW_ANGLES} \"\n",
    "            cmd += f\"--scale {random_scale} --n_occlusions {random_n_occlusions} \"\n",
    "            cmd += f\"--render_engine {_RENDER_ENGINE} \"\n",
    "            cmd += f\"{obj_filepath}\"\n",
    "            out = subprocess.check_output(cmd.split(\" \"), shell=False)\n",
    "            subprocess_outputs.append(out)\n",
    "        else:\n",
    "            print(\"Skipping.\")\n",
    "        \n",
    "        # Stdout\n",
    "        stdout_str = f\"[{img_i+1}/{_N_MODELS_TO_RENDER}] -- \"\n",
    "        stdout_str += f\"SynsetID: {synset_id} -- \"\n",
    "        stdout_str += f\"InstanceID: {instance_id:32s} -- \"\n",
    "        stdout_str += f\"Name: {obj_name}\"\n",
    "        print(stdout_str)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    try:\n",
    "        # Try to cleanup directory with incomplete # renders\n",
    "        if len(os.listdir(output_root)) != _N_VIEW_ANGLES:\n",
    "            shutil.rmtree(output_root)\n",
    "    except:\n",
    "        pass\n",
    "    print(\"\\nEnding early.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_imgs_root = '/hdd/mliuzzolino/Places2/places365_standard/train'\n",
    "background_img_paths = glob.glob(f'{background_imgs_root}/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images and Animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model 18/18...\n",
      "Limit reached. Ending early.\n"
     ]
    }
   ],
   "source": [
    "_LOAD_LIMIT = 18\n",
    "\n",
    "limit_reached = False\n",
    "\n",
    "all_imgs = []\n",
    "rendered_instance_ids = glob.glob(f\"{os.path.join(_OUTPUT_ROOT, _RENDER_ENGINE)}/*/*\")\n",
    "np.random.shuffle(rendered_instance_ids)\n",
    "for rendered_instance_id in rendered_instance_ids:\n",
    "    sys.stdout.write(f\"\\rProcessed model {len(all_imgs)+1}/{_LOAD_LIMIT}...\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Load paths\n",
    "    target_img_paths = np.sort(glob.glob(f\"{rendered_instance_id}/*_target.png\"))\n",
    "    occluded_img_paths = [ele.replace('_target', '_occluded') for ele in target_img_paths]\n",
    "    semantic_seg_paths = [ele.replace('_target', '_semseg') for ele in target_img_paths]\n",
    "    \n",
    "\n",
    "    # Load images\n",
    "    target_imgs = [modules.utils.read_image(img_path) for img_path in target_img_paths]\n",
    "    occluded_imgs = [modules.utils.read_image(img_path) for img_path in occluded_img_paths]\n",
    "    segmentation_imgs = [modules.utils.read_image(img_path) for img_path in semantic_seg_paths]\n",
    "\n",
    "    # Ensure correct number of view angles present\n",
    "    if len(occluded_imgs) != _N_VIEW_ANGLES:\n",
    "        print(f\"\\t**Error: Insufficient angles! Actual: {len(occluded_imgs)} - Expected: {_N_VIEW_ANGLES}\")\n",
    "        continue\n",
    "\n",
    "    # Setup background image\n",
    "    background_img = modules.utils.sample_background_img(background_img_paths, shape=occluded_imgs[0].shape)\n",
    "\n",
    "    # Apply background image\n",
    "    target_imgs = [modules.utils.add_background(rgb_img, seg_img, background_img) \n",
    "                         for rgb_img, seg_img in zip(target_imgs, segmentation_imgs)]\n",
    "    occluded_imgs = [modules.utils.add_background(rgb_img, seg_img, background_img) \n",
    "                         for rgb_img, seg_img in zip(occluded_imgs, segmentation_imgs)]\n",
    "\n",
    "    # Join rgb image with semantic seg image\n",
    "    joined_imgs = [(target, occluded, mask) \n",
    "                       for target, occluded, mask in zip(target_imgs, occluded_imgs, segmentation_imgs)]\n",
    "\n",
    "    # Combine images\n",
    "    joined_imgs = modules.utils.combine_imgs(joined_imgs)\n",
    "    all_imgs.append(joined_imgs)\n",
    "\n",
    "    # Check limit\n",
    "    if len(all_imgs) >= _LOAD_LIMIT:\n",
    "        print(\"\\nLimit reached. Ending early.\")\n",
    "        limit_reached = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all images\n",
    "stacked_imgs = modules.utils.stack_all_imgs(all_imgs, nrow=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = 'test.gif'\n",
    "animation = modules.utils.toAnimation(stacked_imgs, figsize=(12,12), interval=100, savepath=savepath, fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savepath.endswith('gif'):\n",
    "    display(Image(filename=savepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
