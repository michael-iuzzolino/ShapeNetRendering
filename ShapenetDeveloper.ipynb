{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapenet Rendering\n",
    "- Blender script source: https://github.com/panmari/stanford-shapenet-renderer\n",
    "\n",
    "## Semantic Segmentation\n",
    "If rendering a single object, we get a mask (interpretted as a binary segmentation map) for free. However, if we want to render multiple objects, either for rendering our target object into a 3D scene or for using secondary models to produce oclusions, then we need to do something more. \n",
    "\n",
    "Here are some references for how we can do semantic segmentation:\n",
    "- https://blender.stackexchange.com/questions/79595/change-diffuse-shader-to-emission-shader-without-affecting-shader-color\n",
    "- https://blender.stackexchange.com/questions/80906/create-a-segmentation-picture-with-each-object-class-rendered-in-different-color/162746#162746\n",
    "- https://blender.stackexchange.com/questions/34609/is-there-a-way-to-streamline-scripting-these-shaders-and-modifier-keyframes\n",
    "- https://github.com/DIYer22/bpycv#install\n",
    " - This seems promising, but I had issues when trying to install openexr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import imageio\n",
    "import shutil\n",
    "\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "from modules.ShapeNetHandler import ShapeNetHandler\n",
    "import modules.utils\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ShapeNet Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapenet_root = \"/hdd/mliuzzolino/ShapeNet/data/ShapeNetCore.v2\"\n",
    "shapenet_handler = ShapeNetHandler(shapenet_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print available categories by name\n",
    "- Can use name to condition random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapenet_handler.print_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly Sample a filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_obj_filepath, temp_synset_id, temp_instance_id, temp_obj_name = shapenet_handler.sample_obj(category_name='car')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "_OUTPUT_ROOT = 'render_output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N_VIEW_ANGLES = 72\n",
    "_N_MODELS_TO_RENDER = 12\n",
    "_RANDOM_SCALING = False\n",
    "_OVERWRITE = True\n",
    "_RENDER_ENGINE = 'CYCLES' # 'CYCLES', 'BLENDER_RENDER'\n",
    "_RENDER_SCRIPT = \"scripts/blender_render.py\"\n",
    "_TARGET_CATEGORY_LIST = []#['airplane', 'car']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] -- SynsetID: 04225987 -- InstanceID: a34d794cd11272512cba79096b49c1aa -- Name: skateboard\n",
      "[2/12] -- SynsetID: 04004475 -- InstanceID: d80d585502fcb9d3199f2eca998ded6d -- Name: printer,printing machine\n"
     ]
    }
   ],
   "source": [
    "subprocess_outputs = []\n",
    "try:\n",
    "    for img_i in range(_N_MODELS_TO_RENDER):\n",
    "        # Randomly select target category\n",
    "        target_category = ''\n",
    "        if _TARGET_CATEGORY_LIST != []:\n",
    "            target_category = np.random.choice(_TARGET_CATEGORY_LIST)\n",
    "        \n",
    "        # Sample object filepath\n",
    "        obj_filepath, synset_id, instance_id, obj_name = shapenet_handler.sample_obj(category_name=target_category)\n",
    "        \n",
    "        # Setup outpath\n",
    "        output_root = os.path.join(_OUTPUT_ROOT, f'synsetID_{synset_id}', instance_id)\n",
    "        \n",
    "        # Randomly select obj scaling\n",
    "        random_scale = np.random.uniform(0.99, 1.15) if _RANDOM_SCALING else 1.0\n",
    "        random_n_occlusions = np.random.randint(3, 7)\n",
    "        \n",
    "        if not os.path.exists(output_root) or _OVERWRITE:\n",
    "            # Remove previous directory if overwrite\n",
    "            if _OVERWRITE and os.path.exists(output_root):\n",
    "                shutil.rmtree(output_root)\n",
    "            \n",
    "            # Run blender script\n",
    "            cmd = f\"blender --background --python {_RENDER_SCRIPT} -- \"\n",
    "            cmd += f\"--output_folder {output_root} --views {_N_VIEW_ANGLES} \"\n",
    "            cmd += f\"--scale {random_scale} --n_occlusions {random_n_occlusions} \"\n",
    "            cmd += f\"--render_engine {_RENDER_ENGINE} \"\n",
    "            cmd += f\"{obj_filepath}\"\n",
    "            out = subprocess.check_output(cmd.split(\" \"), shell=False)\n",
    "            subprocess_outputs.append(out)\n",
    "        else:\n",
    "            print(\"Skipping.\")\n",
    "        \n",
    "        # Stdout\n",
    "        stdout_str = f\"[{img_i+1}/{_N_MODELS_TO_RENDER}] -- \"\n",
    "        stdout_str += f\"SynsetID: {synset_id} -- \"\n",
    "        stdout_str += f\"InstanceID: {instance_id:32s} -- \"\n",
    "        stdout_str += f\"Name: {obj_name}\"\n",
    "        print(stdout_str)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    try:\n",
    "        # Try to cleanup directory with incomplete # renders\n",
    "        if len(os.listdir(output_root)) != _N_VIEW_ANGLES:\n",
    "            shutil.rmtree(output_root)\n",
    "    except:\n",
    "        pass\n",
    "    print(\"\\nEnding early.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_imgs_root = '/hdd/mliuzzolino/Places2/places365_standard/train'\n",
    "background_img_paths = glob.glob(f'{background_imgs_root}/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images and Animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_background(RGB_img, segmentation_img, background_img):\n",
    "    mask = segmentation_img > 0\n",
    "    RGB_img[np.where(~mask)] = background_img[np.where(~mask)]\n",
    "    return RGB_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_background_img(background_img_paths, shape):\n",
    "    random_background_path = np.random.choice(background_img_paths)\n",
    "    background_img = imageio.imread(random_background_path)\n",
    "    background_img = cv2.resize(background_img, shape[:2][::-1])\n",
    "    return background_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LOAD_LIMIT = 30\n",
    "\n",
    "limit_reached = False\n",
    "\n",
    "all_imgs = []\n",
    "rendered_instance_ids = glob.glob(f\"{_OUTPUT_ROOT}/*/*\")\n",
    "np.random.shuffle(rendered_instance_ids)\n",
    "for rendered_instance_id in rendered_instance_ids:\n",
    "    sys.stdout.write(f\"\\rProcessed model {len(all_imgs)+1}/{_LOAD_LIMIT}...\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Load paths\n",
    "    rendered_img_paths = np.sort(glob.glob(f\"{rendered_instance_id}/*RGBA_full.png\"))\n",
    "    semantic_seg_paths = [ele.replace('_full', '_semantic_segmentation') for ele in rendered_img_paths]\n",
    "\n",
    "    # Load images\n",
    "    rendered_imgs = [modules.utils.read_image(img_path) \n",
    "                         for img_path in rendered_img_paths]\n",
    "    segmentation_imgs = [modules.utils.read_image(img_path)\n",
    "                         for img_path in semantic_seg_paths]\n",
    "\n",
    "    # Ensure correct number of view angles present\n",
    "    if len(rendered_imgs) != _N_VIEW_ANGLES:\n",
    "        print(f\"\\t**Error: Insufficient angles! Actual: {len(rendered_imgs)} - Expected: {_N_VIEW_ANGLES}\")\n",
    "        continue\n",
    "\n",
    "    # Setup background image\n",
    "    background_img = sample_background_img(background_img_paths, shape=rendered_imgs[0].shape)\n",
    "\n",
    "    # Apply background image\n",
    "    rendered_imgs = [add_background(rgb_img, seg_img, background_img) \n",
    "                         for rgb_img, seg_img in zip(rendered_imgs, segmentation_imgs)]\n",
    "\n",
    "    # Join rgb image with semantic seg image\n",
    "    rendered_imgs = [(rgb, mask) for rgb, mask in zip(rendered_imgs, segmentation_imgs)]\n",
    "\n",
    "    # Combine images\n",
    "    combined_imgs = modules.utils.combine_imgs(rendered_imgs)\n",
    "    all_imgs.append(combined_imgs)\n",
    "\n",
    "    # Check limit\n",
    "    if len(all_imgs) >= _LOAD_LIMIT:\n",
    "        print(\"\\nLimit reached. Ending early.\")\n",
    "        limit_reached = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-7ac60392e273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Stack all images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstacked_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_all_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ShapeNetRendering/modules/utils.py\u001b[0m in \u001b[0;36mstack_all_imgs\u001b[0;34m(all_imgs, nrow)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack_all_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mall_imgs_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mall_imgs_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_imgs_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mstacked_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_imgs_pt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "# Stack all images\n",
    "stacked_imgs = modules.utils.stack_all_imgs(all_imgs, nrow=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = 'test.gif'\n",
    "animation = modules.utils.toAnimation(stacked_imgs, figsize=(12,12), interval=100, savepath=savepath, fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savepath.endswith('gif'):\n",
    "    display(Image(filename=savepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
