{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapenet Rendering\n",
    "- Blender script source: https://github.com/panmari/stanford-shapenet-renderer\n",
    "\n",
    "## Semantic Segmentation\n",
    "If rendering a single object, we get a mask (interpretted as a binary segmentation map) for free. However, if we want to render multiple objects, either for rendering our target object into a 3D scene or for using secondary models to produce oclusions, then we need to do something more. \n",
    "\n",
    "Here are some references for how we can do semantic segmentation:\n",
    "- https://blender.stackexchange.com/questions/79595/change-diffuse-shader-to-emission-shader-without-affecting-shader-color\n",
    "- https://blender.stackexchange.com/questions/80906/create-a-segmentation-picture-with-each-object-class-rendered-in-different-color/162746#162746\n",
    "- https://blender.stackexchange.com/questions/34609/is-there-a-way-to-streamline-scripting-these-shaders-and-modifier-keyframes\n",
    "- https://github.com/DIYer22/bpycv#install\n",
    " - This seems promising, but I had issues when trying to install openexr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import imageio\n",
    "import shutil\n",
    "\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "from modules.ShapeNetHandler import ShapeNetHandler\n",
    "import modules.utils\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ShapeNet Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapenet_root = \"/hdd/mliuzzolino/ShapeNet/data/ShapeNetCore.v2\"\n",
    "shapenet_handler = ShapeNetHandler(shapenet_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print available categories by name\n",
    "- Can use name to condition random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapenet_handler.print_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly Sample a filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_obj_filepath, temp_synset_id, temp_instance_id, temp_obj_name = shapenet_handler.sample_obj(category_name='car')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_OUTPUT_ROOT = 'render_output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N_VIEW_ANGLES = 72\n",
    "_N_MODELS_TO_RENDER = 60\n",
    "_RANDOM_SCALING = False\n",
    "_OVERWRITE = True\n",
    "_RENDER_SCRIPT = \"scripts/blender_render.py\"\n",
    "_TARGET_CATEGORY_LIST = []#['airplane', 'car']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/60] -- SynsetID: 02808440 -- InstanceID: b19ff5aaa6a6940b412deb0d2b0f3dcd -- Name: bathtub,bathing tub,bath,tub\n",
      "[2/60] -- SynsetID: 03636649 -- InstanceID: 273314626729b1e973222d877df1ecac -- Name: lamp\n",
      "[3/60] -- SynsetID: 03513137 -- InstanceID: ae8a2ae90ac11bd93d4e343a1ac21b93 -- Name: helmet\n",
      "[4/60] -- SynsetID: 03948459 -- InstanceID: e3f45b75b688bf33794921644e32aee6 -- Name: pistol,handgun,side arm,shooting iron\n",
      "[5/60] -- SynsetID: 03046257 -- InstanceID: 637237e978d5168f9751189c905e470  -- Name: clock\n",
      "[6/60] -- SynsetID: 03211117 -- InstanceID: a3ada0a8bc0d4b8392ababf87635e60c -- Name: display,video display\n",
      "[7/60] -- SynsetID: 02691156 -- InstanceID: 1f672d2fd5e3f4e78026abe712c1ab05 -- Name: airplane,aeroplane,plane\n",
      "[8/60] -- SynsetID: 02871439 -- InstanceID: 61ebec53da40801f99e8bf807e902261 -- Name: bookshelf\n",
      "[9/60] -- SynsetID: 02747177 -- InstanceID: 2ac7a4d88dfedcfef155d75bbf62b80  -- Name: ashcan,trash can,garbage can,wastebin,ash bin,ash-bin,ashbin,dustbin,trash barrel,trash bin\n",
      "[10/60] -- SynsetID: 03710193 -- InstanceID: ab94303f7fad5b453b02598625ec1bf7 -- Name: mailbox,letter box\n",
      "[11/60] -- SynsetID: 04225987 -- InstanceID: 58ab8327f188e0a063381d3d7e871939 -- Name: skateboard\n",
      "[12/60] -- SynsetID: 03642806 -- InstanceID: ebc59a9b4291ce274c3c121820623e4e -- Name: laptop,laptop computer\n",
      "[13/60] -- SynsetID: 04256520 -- InstanceID: 698a0a47dd9bba797ddb7abd4c043364 -- Name: sofa,couch,lounge\n",
      "[14/60] -- SynsetID: 04256520 -- InstanceID: 9b651dee9548be90ded526a7be77b30e -- Name: sofa,couch,lounge\n",
      "[15/60] -- SynsetID: 04090263 -- InstanceID: 365ed0964805ef59f5cbed688a0bb106 -- Name: rifle\n",
      "[16/60] -- SynsetID: 04099429 -- InstanceID: 4936716925b1cd6428eba1f0b7744e9  -- Name: rocket,projectile\n",
      "[17/60] -- SynsetID: 04401088 -- InstanceID: 27b4f430b881e16ad6339cac3214b6bf -- Name: telephone,phone,telephone set\n",
      "[18/60] -- SynsetID: 03593526 -- InstanceID: 2fc5fff977ac930050b92125e5fcb8ac -- Name: jar\n",
      "[19/60] -- SynsetID: 02954340 -- InstanceID: a3d8771740fd7630afd6b353b2d4958f -- Name: cap\n",
      "[20/60] -- SynsetID: 04330267 -- InstanceID: e30e4f8c9383b4b3a805114916841d69 -- Name: stove\n",
      "[21/60] -- SynsetID: 03691459 -- InstanceID: fae47d104b9111aafd949ebbd292d47  -- Name: loudspeaker,speaker,speaker unit,loudspeaker system,speaker system\n",
      "[22/60] -- SynsetID: 02818832 -- InstanceID: ab9e57b316f43962b738ef7a6757633a -- Name: bed\n",
      "[23/60] -- SynsetID: 02958343 -- InstanceID: d9867d92edba3d0cb96212c8f6cd06e  -- Name: car,auto,automobile,machine,motorcar\n",
      "[24/60] -- SynsetID: 03046257 -- InstanceID: 253156f6fea2d869ff59f04994ef1f0c -- Name: clock\n",
      "[25/60] -- SynsetID: 03761084 -- InstanceID: c57ce5ac1f4f5e127bae653f822044a6 -- Name: microwave,microwave oven\n",
      "[26/60] -- SynsetID: 03593526 -- InstanceID: 7f355d9510fbe2b02af07f81a2ca6736 -- Name: jar\n",
      "[27/60] -- SynsetID: 03261776 -- InstanceID: 26e186ab10abad8ee6873d49607c1f87 -- Name: earphone,earpiece,headphone,phone\n",
      "[28/60] -- SynsetID: 02843684 -- InstanceID: a448fb21ce07c5332cba66dc6aeabcd4 -- Name: birdhouse\n",
      "[29/60] -- SynsetID: 04554684 -- InstanceID: aef595f6f7c14cf4fe43ff1e45af424d -- Name: washer,automatic washer,washing machine\n",
      "[30/60] -- SynsetID: 02958343 -- InstanceID: 2928f77d711bf46eaa69dfdc5532bb13 -- Name: car,auto,automobile,machine,motorcar\n",
      "[31/60] -- SynsetID: 03001627 -- InstanceID: 6829ec525eab85671f2351826b1ffa67 -- Name: chair\n",
      "[32/60] -- SynsetID: 03211117 -- InstanceID: 946ec8b571ca42d378838533e331d3cf -- Name: display,video display\n",
      "[33/60] -- SynsetID: 03636649 -- InstanceID: ae67ee6392fe8ab94e7cb04dd663c825 -- Name: lamp\n",
      "[34/60] -- SynsetID: 03710193 -- InstanceID: 655cc66caed0a4759c0d8b17a41b6f3  -- Name: mailbox,letter box\n",
      "[35/60] -- SynsetID: 03938244 -- InstanceID: 359576c82de003cf96907985b34a7ba3 -- Name: pillow\n",
      "[36/60] -- SynsetID: 03797390 -- InstanceID: b4ae56d6638d5338de671f28c83d2dcb -- Name: mug\n",
      "[37/60] -- SynsetID: 02828884 -- InstanceID: 7f6db7a3f529949601104cd2d998272  -- Name: bench\n",
      "[38/60] -- SynsetID: 02954340 -- InstanceID: 18387b36aa7b2d4af0d11ae402ef940e -- Name: cap\n",
      "[39/60] -- SynsetID: 03761084 -- InstanceID: 48eecde6f71bc1a2f99d92708f91e592 -- Name: microwave,microwave oven\n",
      "[40/60] -- SynsetID: 03928116 -- InstanceID: eb99228ff23aa9f9c6543c981120ca48 -- Name: piano,pianoforte,forte-piano\n",
      "[41/60] -- SynsetID: 04004475 -- InstanceID: b13d7229f113cc6fa3ac1bbe37d03a29 -- Name: printer,printing machine\n"
     ]
    }
   ],
   "source": [
    "subprocess_outputs = []\n",
    "try:\n",
    "    for img_i in range(_N_MODELS_TO_RENDER):\n",
    "        # Randomly select target category\n",
    "        target_category = ''\n",
    "        if _TARGET_CATEGORY_LIST != []:\n",
    "            target_category = np.random.choice(_TARGET_CATEGORY_LIST)\n",
    "        \n",
    "        # Sample object filepath\n",
    "        obj_filepath, synset_id, instance_id, obj_name = shapenet_handler.sample_obj(category_name=target_category)\n",
    "        \n",
    "        # Setup outpath\n",
    "        output_root = os.path.join(_OUTPUT_ROOT, f'synsetID_{synset_id}', instance_id)\n",
    "        \n",
    "        # Randomly select obj scaling\n",
    "        random_scale = np.random.uniform(0.99, 1.15) if _RANDOM_SCALING else 1.0\n",
    "        random_n_occlusions = np.random.randint(3, 7)\n",
    "        \n",
    "        if not os.path.exists(output_root) or _OVERWRITE:\n",
    "            # Remove previous directory if overwrite\n",
    "            if _OVERWRITE and os.path.exists(output_root):\n",
    "                shutil.rmtree(output_root)\n",
    "            \n",
    "            # Run blender script\n",
    "            cmd = f\"blender --background --python {_RENDER_SCRIPT} -- \"\n",
    "            cmd += f\"--output_folder {output_root} --views {_N_VIEW_ANGLES} \"\n",
    "            cmd += f\"--scale {random_scale} --n_occlusions {random_n_occlusions} \"\n",
    "            cmd += f\"{obj_filepath}\"\n",
    "            out = subprocess.check_output(cmd.split(\" \"), shell=False)\n",
    "            subprocess_outputs.append(out)\n",
    "        else:\n",
    "            print(\"Skipping.\")\n",
    "        \n",
    "        # Stdout\n",
    "        stdout_str = f\"[{img_i+1}/{_N_MODELS_TO_RENDER}] -- \"\n",
    "        stdout_str += f\"SynsetID: {synset_id} -- \"\n",
    "        stdout_str += f\"InstanceID: {instance_id:32s} -- \"\n",
    "        stdout_str += f\"Name: {obj_name}\"\n",
    "        print(stdout_str)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    try:\n",
    "        # Try to cleanup directory with incomplete # renders\n",
    "        if len(os.listdir(output_root)) != _N_VIEW_ANGLES:\n",
    "            shutil.rmtree(output_root)\n",
    "    except:\n",
    "        pass\n",
    "    print(\"\\nEnding early.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_imgs_root = '/hdd/mliuzzolino/Places2/places365_standard/train'\n",
    "background_img_paths = glob.glob(f'{background_imgs_root}/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images and Animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_background(RGB_img, segmentation_img, background_img):\n",
    "    mask = segmentation_img > 0\n",
    "    RGB_img[np.where(~mask)] = background_img[np.where(~mask)]\n",
    "    return RGB_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_background_img(background_img_paths, shape):\n",
    "    random_background_path = np.random.choice(background_img_paths)\n",
    "    background_img = imageio.imread(random_background_path)\n",
    "    background_img = cv2.resize(background_img, shape[:2][::-1])\n",
    "    return background_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['render_output/synsetID_02691156/10af5de930178a161596c26b5af806fe',\n",
       " 'render_output/synsetID_02691156/7f4b166fba71407490b1d6deb98feec6',\n",
       " 'render_output/synsetID_02691156/3ecea45bfa541b8e4a4dd08ffc16eb81',\n",
       " 'render_output/synsetID_02691156/b8e4e4994d4674cf2023ec956848b741',\n",
       " 'render_output/synsetID_02691156/9d65814e1b252fb01636caafca838500',\n",
       " 'render_output/synsetID_02691156/27c409ead0c4e34c9a6e43b878d5b335',\n",
       " 'render_output/synsetID_02691156/420f3bb771e8e75ed878249aca2571f',\n",
       " 'render_output/synsetID_02691156/8bde5a00c3caf9771d03b466c72ce41',\n",
       " 'render_output/synsetID_02691156/8259a1fdcb9bca7526360e1e29a956c7',\n",
       " 'render_output/synsetID_02691156/1cc3ebbadfe69e8011f5789deac2dcac',\n",
       " 'render_output/synsetID_02691156/1d63eb2b1f78aa88acf77e718d93f3e1',\n",
       " 'render_output/synsetID_02691156/48e477d5904bb7bb1ad94eee1d03defc',\n",
       " 'render_output/synsetID_02691156/41c7470ce9ecb74b6f9423fcc87803f2',\n",
       " 'render_output/synsetID_02691156/e8e1b765fdf5edfa14c19f41d007670e',\n",
       " 'render_output/synsetID_02691156/559f9a545b9b98a1d433b2698458193',\n",
       " 'render_output/synsetID_02691156/350110d2828b3b927370804727e72eb2']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendered_instance_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['render_output/synsetID_02691156', 'render_output/synsetID_02958343']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendered_synset_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model 15/15...\n",
      "Limit reached. Ending early.\n"
     ]
    }
   ],
   "source": [
    "_LOAD_LIMIT = 15\n",
    "\n",
    "limit_reached = False\n",
    "\n",
    "all_imgs = []\n",
    "rendered_instance_ids = glob.glob(f\"{_OUTPUT_ROOT}/*/*\")\n",
    "np.random.shuffle(rendered_instance_ids)\n",
    "for rendered_instance_id in rendered_instance_ids:\n",
    "    sys.stdout.write(f\"\\rProcessed model {len(all_imgs)+1}/{_LOAD_LIMIT}...\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Load paths\n",
    "    rendered_img_paths = np.sort(glob.glob(f\"{rendered_instance_id}/*RGBA_full.png\"))\n",
    "    semantic_seg_paths = [ele.replace('_full', '_semantic_segmentation') for ele in rendered_img_paths]\n",
    "\n",
    "    # Load images\n",
    "    rendered_imgs = [modules.utils.read_image(img_path) \n",
    "                         for img_path in rendered_img_paths]\n",
    "    segmentation_imgs = [modules.utils.read_image(img_path)\n",
    "                         for img_path in semantic_seg_paths]\n",
    "\n",
    "    # Ensure correct number of view angles present\n",
    "    if len(rendered_imgs) != _N_VIEW_ANGLES:\n",
    "        print(f\"\\t**Error: Insufficient angles! Actual: {len(rendered_imgs)} - Expected: {_N_VIEW_ANGLES}\")\n",
    "        continue\n",
    "\n",
    "    # Setup background image\n",
    "    background_img = sample_background_img(background_img_paths, shape=rendered_imgs[0].shape)\n",
    "\n",
    "    # Apply background image\n",
    "    rendered_imgs = [add_background(rgb_img, seg_img, background_img) \n",
    "                         for rgb_img, seg_img in zip(rendered_imgs, segmentation_imgs)]\n",
    "\n",
    "    # Join rgb image with semantic seg image\n",
    "    rendered_imgs = [(rgb, mask) for rgb, mask in zip(rendered_imgs, segmentation_imgs)]\n",
    "\n",
    "    # Combine images\n",
    "    combined_imgs = modules.utils.combine_imgs(rendered_imgs)\n",
    "    all_imgs.append(combined_imgs)\n",
    "\n",
    "    # Check limit\n",
    "    if len(all_imgs) >= _LOAD_LIMIT:\n",
    "        print(\"\\nLimit reached. Ending early.\")\n",
    "        limit_reached = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all images\n",
    "stacked_imgs = modules.utils.stack_all_imgs(all_imgs, nrow=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building animator...\n",
      "Generating animation object...\n",
      "Saving to test.gif...\n",
      "Fin.\n"
     ]
    }
   ],
   "source": [
    "savepath = 'test.gif'\n",
    "animation = modules.utils.toAnimation(stacked_imgs, figsize=(12,12), interval=100, savepath=savepath, fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savepath.endswith('gif'):\n",
    "    display(Image(filename=savepath))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
